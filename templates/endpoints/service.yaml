name: endpoints
ray_serve_config:
  applications:
  - name: my-endpoints
    route_prefix: /
    import_path: rayllm.backend:router_application
    args:
      models:
        # Link to list of models you want to serve here. You can add more than one model
        - "./models/meta-llama--Llama-2-7b-chat-hf_a10.yaml"
    runtime_env:
      env_vars:
        HUGGING_FACE_HUB_TOKEN: "UPDATE HF TOKEN HERE"
