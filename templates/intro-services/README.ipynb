{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Services\n",
    "\n",
    "**⏱️ Time to complete**: 5 min (15 on GCP)\n",
    "\n",
    "This tutorial shows you how to:\n",
    "1. Develop a simple Ray Serve app in a workspace.\n",
    "2. Deploy the app to production as an Anyscale Service.\n",
    "3. Monitor the production app.\n",
    "4. Configure service scaling.\n",
    "\n",
    "**Note**: This tutorial runs in a workspace. See `Introduction to Workspaces` before running this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop a Serve app in a workspace\n",
    "\n",
    " The fastest way to develop a Ray Serve app is in an Anyscale Workspace. A Serve app running within a workspace behaves almost identically to a Serve app running as a production service, except that it doesn't have a stable DNS name or fault tolerance.\n",
    "\n",
    " Look at the `main.py` file, which has the following skeleton code:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from fastapi import FastAPI\n",
    "from ray import serve\n",
    "\n",
    "fastapi = FastAPI()\n",
    "\n",
    "@serve.deployment\n",
    "@serve.ingress(fastapi)\n",
    "class FastAPIDeployment:\n",
    "    # FastAPI automatically parses the HTTP request.\n",
    "    # See https://docs.ray.io/en/latest/serve/http-guide.html\n",
    "    @fastapi.get(\"/hello\")\n",
    "    def say_hello(self, name: str) -> str:\n",
    "        return f\"Hello {name}!\"\n",
    "\n",
    "my_app = FastAPIDeployment.bind()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the app in the workspace\n",
    "Use the command below to run the Serve app in the workspace on `localhost:8000`.\n",
    "\n",
    "If you want to run it again, use the same command to update the app.\n",
    "\n",
    "**Tip**: Use `serve run main:my_app --blocking` in a new VSCode terminal to block and print out application logs (exceptions, etc.) in the terminal, allowing you to view Serve backend logs more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!serve run main:my_app --non-blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send a test request\n",
    "Run the following cell to query the workspace Ray Serve app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "print(requests.get(\"http://localhost:8000/hello\", params={\"name\": \"Theodore\"}).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to production as a service\n",
    "\n",
    "To enable fault tolerance and expose your app to the public internet, you must \"deploy\" the app, which creates an Anyscale Service backed by a public load balancer. This service deploys in a separate Ray Cluster, not in the workspace, and the Anyscale control plane monitors it to recover on node failures. You can also deploy rolling updates to the service without incurring downtime.\n",
    "\n",
    "Use the following command to deploy your app as `my_service`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!serve deploy main:my_app --name=my_service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: If your app has PyPI dependencies that you added from the workspace, `serve deploy` automatically compiles these dependencies into a Docker image prior to deploying to optimize startup time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Overview page in the console\n",
    "\n",
    "Navigate to your newly created service in the Anyscale console at **Home > Services > my_service**. It should be in the \"Starting\" state. Click the service name and wait for the service to enter the \"Running\" state.\n",
    "\n",
    "You should see the service state, key metrics, and system event logs on the Overview page.\n",
    "\n",
    "<img src=\"assets/service-overview.png\" height=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query from the public internet\n",
    "\n",
    "Once the service is running, query the service from the public internet using similar logic from the test query in the development workspace. Make two changes:\n",
    "1. Update the `HOST` to the service endpoint.\n",
    "2. Add the authorization token as a header in the HTTP request.\n",
    "\n",
    "To find the `HOST` and authorization token values, run `serve deploy`, or find them on the service page. For example, for the following output of `serve deploy`:\n",
    "- The service endpoint value is: `https://stable_diffusion_app-4rq8m.cld-ltw6mi8dxaebc3yf.s.anyscaleuserdata-staging.com`.\n",
    "- The authorization token value is: `26hTWi2kZwEz0Tdi1_CKRep4NLXbuuaSTDb3WMXK9DM`.\n",
    "ru\n",
    "```bash\n",
    "(anyscale +4.0s) You can query the service endpoint using the curl request below:\n",
    "(anyscale +4.0s) curl -H 'Authorization: Bearer 26hTWi2kZwEz0Tdi1_CKRep4NLXbuuaSTDb3WMXK9DM' https://stable_diffusion_app-4rq8m.cld-ltw6mi8dxaebc3yf.s.anyscaleuserdata-staging.com\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "HOST = \"TODO_INSERT_YOUR_SERVICE_HOST\"\n",
    "TOKEN = \"TODO_INSERT_YOUR_SERVICE_TOKEN\"\n",
    "\n",
    "def send_request(name: str) -> str:\n",
    "    response: requests.Response = requests.get(\n",
    "        f\"{HOST}/hello\",\n",
    "        params={\"name\": name},\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "        },\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(send_request(\"Theodore\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor production services\n",
    "\n",
    "Along with the monitoring tools that come with workspaces, services provide additional built-in metrics that you can find in the `Metrics` tab. This tab includes aggregated metrics across all rollouts for a service, possibly from multiple Ray clusters.\n",
    "\n",
    "<img src=\"assets/service-metrics.png\" height=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure service scaling\n",
    "\n",
    "By default, a service has a single replica. To change this configuration, set the `num_replicas` argument in the [serve.deployment decorator](https://docs.ray.io/en/latest/serve/configure-serve-deployment.html) as follows in `main.py`.\n",
    "\n",
    "```python\n",
    "@serve.deployment(num_replicas=4)\n",
    "@serve.ingress(fastapi)\n",
    "class FastAPIDeployment:\n",
    "    ...\n",
    "```\n",
    "\n",
    " For more advanced scaling options, see [Ray Serve Autoscaling](https://docs.ray.io/en/latest/serve/autoscaling-guide.html#serve-autoscaling).\n",
    " \n",
    "Rerun the service in the development workspace using `serve run`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!serve run main:my_app --non-blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the increase in the number of replicas in the Ray Dashboard of the development workspace:\n",
    "\n",
    "<img src=\"assets/serve-replicas.png\" height=400px/>\n",
    "\n",
    "On the production service, deploy the update, making sure to include the `--name` option to specify which service to deploy to. This command triggers a staged rollout of the service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!serve deploy main:my_app --name=my_service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor the status of the rollout in the service Overview page. Once the new Ray Cluster with the updated app config is running, Ray Serve shuts down the previous cluster:\n",
    "\n",
    "<img src=\"assets/service-rollout.png\" height=300px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Ray Serve scaling vs Ray cluster configs\n",
    "\n",
    "When scaling your service, the Serve autoscaling config, from `@serve.deployment`, interacts with the compute config, which contains the number of worker nodes. Generally, the compute config is an upper bound on service autoscaling, because Ray Serve runs inside an Anyscale Cluster.\n",
    "\n",
    "For example, if you configure the Ray Cluster to have at most 100 CPUs, then Serve can only launch up to 100 replicas, regardless of the scaling config.\n",
    "\n",
    "For this reason, enable the \"Auto-select machines\" cluster config for services. This setting is on by default.\n",
    "\n",
    "#### Edit a service cluster config\n",
    "\n",
    "When Anyscale first creates a service, it copies the cluster config from the workspace. After that, Anyscale decouples the service cluster config from the workspace and you can edit it independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more, try other model serving templates available in the template gallery, and the Ray Serve [documentation](https://docs.ray.io/en/latest/serve/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook you:\n",
    "- Developed and ran a simple Ray Serve app in a development workspace.\n",
    "- Deployed the app to production as a service.\n",
    "- Monitored the service.\n",
    "- Scaled the service that uses both the Ray Serve config and Ray Cluster config together."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
